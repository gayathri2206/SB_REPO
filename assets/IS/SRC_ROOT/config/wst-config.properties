pg.keystore.keyStoreHandle=
pg.keystore.trustStoreHandle=
#  target name is used to identify this CloudStreams Engine
pg.policygateway.targetName=your-target-name-here
#
pg.policygateway.repositoryLocation=repository
pg.proxyLoader.proxyLocation=proxies
 #0 indicates the service reader is disabled (to enable specify value in ms e.g. 15000 for 15 secs)
pg.serviceReader.interval=0
pg.jaxbFileStore.consumerFileStore=resources/consumers/consumers.xml
pg.jaxbNamesStore.namesFileStore=resources/consumers/registeredNames.xml
cls.jaxbCollectionKeysStore.namesFileStore=resources/connectors/cls-collectionKeys.xml

pg.debug.eventLoggerActive=false

#  The deployment receiver temporarily persist some artifacts,
#    should they be retained?  Default is true/yes.
pg.policygateway.deploy.receiver.deleteTempArtifacts=true

# email server
pg.email.SenderActive=false
pg.email.smtpHost=
# email port for smtp/smtps protocol
pg.email.smtpPort=25
# sender email address to use when sending email events 
pg.email.from=
# for authenticated email account
pg.email.userName=
# uses one-way encryption. 
# The mediator trust store must include a cert from the email server's chain.
pg.email.TLSEnabled=false
# additional debug details
pg.email.debug=false
# mime type to use when creating email attachments
pg.email.resourceMimeType=application/zip
# used for send and connection timeouts in milliseconds
pg.email.timeOut=1000
# char set to use for subject line, email addresses and message body
pg.email.charSet=US-ASCII

#
#  CloudStreams Engine startup cannot complete (services can't be deployed, CS can't be
#    queried for updates) until IS is up and running.  If IS is not yet
#    fully operational when CloudStreams Engine starts up, a delayed refresh helper is
#    used to wait for IS.  This helper will periodically check on IS.  This
#    'napMillis' property specifies how long the helper sleeps between checks.
pg.delayedRefresher.napMillis=500

#The path to the ehcache config file; this will be provided to IS the first time
#and further startups will not use the local file, but the one under IS/config/Caching
pg.ehcache.config.file=resources/caching/SoftwareAG-IS-CloudStreams.xml

#
# How many seconds will shared cache wait to obtain a lock before giving up
pg.PgMenSharedCacheManager.lockTimeOut=5
pg.PgMenSharedCacheManager.lockRetry=1
# How many minutes for performance data publish interval
pg.PgMenConfiguration.reportInterval=60
# Is performance data collection enabled?
pg.PgMenConfiguration.perfDataEnabled=false
# How many seconds between each interval processor iteration. This must be
# an evenly divisible fraction of the smallest policy interval which is one minute
pg.PgMenConfiguration.tickInterval=15
# How many seconds before accumulated invoked service events are pushed into shared cache
pg.PgMenConfiguration.sieFlushInterval=2
# How many sie's are cached locally for a virtual service before they are flushed to shared cache
pg.PgMenConfiguration.sieFlushThreshold=50
# Three flags to determine whether different event types should be published
pg.PgMenConfiguration.publishLifeCycleEvents=false
pg.PgMenConfiguration.publishErrorEvents=false
pg.PgMenConfiguration.publishPolicyViolationEvents=false
# Are service faults included in the performance data aggregated metric counts?
pg.PgMetricsFormatter.includeFaults=false
# How many milliseconds do we delay before sending a pdu or closing the socket. (0 implies no wait)
# Example: We do not wait by default since CentraSite has an asynchronous queue implementation.
pg.csSnmpSender.sendDelay=0
# How many milliseconds do we delay before sending a pdu or closing the socket. (0 implies no wait)
pg.3pSnmpSender.sendDelay=0
# pgmen data collection work queue minimum thread count
pg.CollectionPool.minThreads=1
# pgmen data collection work queue maximum thread count
pg.CollectionPool.maxThreads=8
# pgmen data collection thread pool will shutdown immediately since dependent resources are going down too.
pg.CollectionPool.forcefulShutdown=true
# Name for the pgmen data collection thread pool
pg.CollectionPool.poolName=CollectionPool
# Capacity for enqueued tasks of the data collection in memory work queue 
pg.CollectionWorkQueue.queueCapacity=10000
# Interval pool is used for scheduled processing of recurring tasks
# minimum thread count for this pool
pg.IntervalPool.minThreads=1
# maximum thread count for this pool
pg.IntervalPool.maxThreads=1
# Does pgmen interval thread pool shutdown immediately or wait for enqueued tasks to complete during
# mediator shutdown? Set to true since dependent resources are going down.
pg.IntervalPool.forcefulShutdown=true
# Name of the pgmen interval processor pool.
pg.IntervalPool.poolName=IntervalPool
# Reporting Pool options affect outbound event publishing 
# At this time, the pool includes all events ( performance data, snmp, smtp, etc. )
# These configuration values affect its thread pool/work queue operations in the same
# manner as the data collection pool and queue. Please see those similar values above for
# more details. 
pg.ReportingPool.minThreads=2
pg.ReportingPool.maxThreads=4
# Set to true since dependent resources are going down at the same time.
pg.ReportingPool.forcefulShutdown=true
pg.ReportingPool.poolName=ReportingPool
pg.ReportingWorkQueue.queueCapacity=5000
#
pg.rampartdeploymenthandler.signingCertAlias=
pg.rampartdeploymenthandler.usernameTokenUser=
#
pg.lb.http.url=
pg.lb.https.url=

# if no value exists, the runtime will default to the currently defined
# primary listener as defined by IS
pg.http.ports=
pg.https.ports=

#backup failed services, by default it is true
pg.backupFailedProxies=true
# can be absolute path or relative to the config directory
pg.failedProxies.backupDir=failed_proxies

#Specifies if CloudStreams Engine should try the next load-balanced endpoint only if current failing endpoint
#was 'down' or failover no matter what exception (soap fault) is got back from backend service
#false, by default - any exception encountered will cause CloudStreams Engine to try next endpoint
#set it to 'true' to make CloudStreams Engine failover only for 'downtime' errors (like Connect Exception)
pg.lb.failoverOnDowntimeErrorOnly=false

#CloudStreams specific properties
wst.product.name=CloudStreams
#Set this to true to see TCPMon-ish output server log
wst.connfactory.wirelogEnabled=false
#If true, events will be sent to Cloudstreams JDBC tables, policies permitting
pg.jdbc.active=false
# The Jdbc sender will send no more than this many records in its batches
pg.jdbc.batchSize=25
# The default tenant integer id to use for this CloudStreams instance 
wst.default.tenant.id=0

# Default Json formatter/builder operation mode, with wrap mode 'true'
wst.rest.json.operationMode=caching


# Property to turn on/off SOAP/REST based request/response payload validation.
# Default value is false (i.e. validates the request and response against the IS doc types)
wst.cloudConnectorService.validation=false

# VSD Transformation XSL style sheet path
pg.vsdTransformer.xslFilePath=

# Large Data configuration related properties. If binaryStreamEnabled then only binaryStreamThreshold is used.
# By default threshold is of size 5MB. Note that payload greater than threshold will not be logged into DB and server logs.
wst.largedata.binaryStreamEnabled=false
wst.largedata.threshold=5242880
